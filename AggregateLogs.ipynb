{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8beee8c0-f88b-4062-8664-c0c097931b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the purpose of this notebook is to explore the separated 10m, 30m, and 50m datasets and their aggregate data (average\n",
    "# pitch/roll, variance in turbulence, battery loss, all that jazz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fdd4919d-453c-44b0-8e4b-ac3b13047bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0953873f-616d-4c16-a172-c73158399b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix individual logs\n",
    "# running the function(s) below, I found that Jan07.3-35_10m and Jan06.4-47_30m had mistakenly collected data on the way DOWN, too, which confounds\n",
    "# the data. here, we reassign that file itself but without the distracting irrelevant data\n",
    "\n",
    "badfile1 = pd.read_csv(Path('UsableLogs/Jan07.3-35_10m.csv'))\n",
    "badfile1 = badfile1[badfile1['index'] <= 381]\n",
    "badfile1.to_csv('UsableLogs/Jan07.3-35_10m.csv', index=False)\n",
    "\n",
    "badfile2 = pd.read_csv(Path('UsableLogs/Jan06.4-47_30m.csv'))\n",
    "badfile2 = badfile2[badfile2['index'] <= 603]\n",
    "badfile2.to_csv('UsableLogs/Jan06.4-47_30m.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "adbec1f4-aafe-4844-9fe0-0958ed3e30eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes a 5-second window of raw data and returns the exact feature dictionary  needed for the Random Forest.\n",
    "\n",
    "def extract_features(window):\n",
    "    # 1. Vector Yaw (The Fix)\n",
    "    # Handles the 0/360 degree wrap-around bug\n",
    "    compass_rads = np.radians(window['compass_heading(degrees)'])\n",
    "    yaw_sd = np.sqrt(np.sin(compass_rads).std()**2 + np.cos(compass_rads).std()**2)\n",
    "    \n",
    "    # 2. Power Stats\n",
    "    # Power = Voltage * Current\n",
    "    power_watts = window['voltage(v)'] * window['current(A)']\n",
    "    p_mean = power_watts.mean()\n",
    "    p_std = power_watts.std()\n",
    "    \n",
    "    # 3. Tilt Stats\n",
    "    # Calculate Magnitude if not already present\n",
    "    if 'tilt_magnitude' not in window.columns:\n",
    "        tilt_mag = np.sqrt(window['pitch(degrees)']**2 + window['roll(degrees)']**2)\n",
    "    else:\n",
    "        tilt_mag = window['tilt_magnitude']\n",
    "        \n",
    "    tilt_mean = tilt_mag.mean()\n",
    "    tilt_std = tilt_mag.std()\n",
    "    \n",
    "    # 4. Return the Dictionary (Keys must match CSV columns EXACTLY)\n",
    "    return {\n",
    "        'speed_avg': window['speed(mph)'].mean(),\n",
    "        'speed_sd': window['speed(mph)'].std(),\n",
    "        'zSpeed_sd': window['zSpeed(mph)'].std(),\n",
    "        'yaw_sd': yaw_sd,            \n",
    "        'power_avg': p_mean,\n",
    "        'power_sd': p_std,\n",
    "        'power_intensity': p_std / (p_mean + 0.05),\n",
    "        'tilt_avg': tilt_mean,\n",
    "        'tilt_sd': tilt_std,\n",
    "        'turbulence_intensity': tilt_std / (tilt_mean + 0.05)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "74bb2f27-2067-4b78-a226-784bd1683276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that turns the files fed into it into a single row of aggregate data\n",
    "\n",
    "# if file ends with _10m, entry in 'altitude' section is 10m, etc.\n",
    "# include file name to check weird outliers out\n",
    "# find average of all speeds, voltage, current, pitch, roll, battery_percent lost over time\n",
    "# each time, append the row to the dataframe previously made\n",
    "\n",
    "directory = Path('UsableLogs')\n",
    "preaggregate_logs = directory.glob('*.csv')\n",
    "output_dir = Path('AggregateLogs')\n",
    "\n",
    "def process_usable_logs():\n",
    "    aggregated_data = []\n",
    "\n",
    "    for file_path in preaggregate_logs:        \n",
    "        # Parse altitude from filename\n",
    "        altitude = None\n",
    "        if '_10m' in file_path.name:\n",
    "            altitude = 10\n",
    "        elif '_30m' in file_path.name:\n",
    "            altitude = 30\n",
    "        elif '_50m' in file_path.name:\n",
    "            altitude = 50\n",
    "        \n",
    "        try:\n",
    "            # Read the CSV\n",
    "            df = pd.read_csv(file_path)\n",
    "            start_time, end_time = pd.to_datetime(df['timestamp'].iloc[0]), pd.to_datetime(df['timestamp'].iloc[-1])\n",
    "            flight_time = (end_time - start_time).total_seconds()\n",
    "            df['tilt_magnitude'] = np.sqrt(df['pitch(degrees)']**2 + df['roll(degrees)']**2)\n",
    "            df['power(watt)'] = df['voltage(v)'] * df['current(A)']\n",
    "            \n",
    "            # calculate the aggregate stats\n",
    "            stats = {\n",
    "                'file_name': file_path.stem,\n",
    "                'flight_time(seconds)': flight_time,\n",
    "                'altitude(m)': altitude,\n",
    "                'zSpeed_avg': df['zSpeed(mph)'].mean(),\n",
    "                'zSpeed_sd': df['zSpeed(mph)'].std(),\n",
    "                'speed_avg': df['speed(mph)'].mean(),\n",
    "                'speed_sd': df['speed(mph)'].std(),\n",
    "                'power_avg': df['power(watt)'].mean(),\n",
    "                'power_sd': df['power(watt)'].std(),\n",
    "                'power_intensity': df['power(watt)'].std() / (df['power(watt)'].mean() + 0.05),\n",
    "                'tilt_avg': df['tilt_magnitude'].mean(),\n",
    "                'tilt_sd': df['tilt_magnitude'].std(),\n",
    "                'turbulence_intensity': df['tilt_magnitude'].std() / (df['tilt_magnitude'].mean() + 0.05) # + 0.05 to avoid div by zero\n",
    "\n",
    "            }\n",
    "            \n",
    "            aggregated_data.append(stats)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path.name}: {e}\")\n",
    "\n",
    "    return pd.DataFrame(aggregated_data).sort_values('file_name')\n",
    "aggregate_df = process_usable_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f0d9fc10-4623-46fa-8dd1-07560362d940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that turns the files fed into it into a several more rows of data to feed to the random forest model.\n",
    "# uses a sliding window to collect data at every 5 second interval (only moving forward 0.5 seconds per step, leading\n",
    "# to more overlap for more thorough data). naming conventions and other data collected is otherwise similar\n",
    "\n",
    "directory = Path('UsableLogs')\n",
    "preaggregate_logs = directory.glob('*.csv')\n",
    "output_dir = Path('')\n",
    "\n",
    "def apply_window_to_usable_logs():\n",
    "    windowed_data = []\n",
    "\n",
    "    for file_path in preaggregate_logs:        \n",
    "        # Parse altitude from filename\n",
    "        altitude = None\n",
    "        if '_10m' in file_path.name:\n",
    "            altitude = 10\n",
    "        elif '_30m' in file_path.name:\n",
    "            altitude = 30\n",
    "        elif '_50m' in file_path.name:\n",
    "            altitude = 50\n",
    "        \n",
    "        try:\n",
    "            # Read the CSV\n",
    "            df = pd.read_csv(file_path)\n",
    "            start_time, end_time = pd.to_datetime(df['timestamp'].iloc[0]), pd.to_datetime(df['timestamp'].iloc[-1])\n",
    "            flight_time = (end_time - start_time).total_seconds()\n",
    "            df['tilt_magnitude'] = np.sqrt(df['pitch(degrees)']**2 + df['roll(degrees)']**2)\n",
    "            df['power(watt)'] = df['voltage(v)'] * df['current(A)']\n",
    "\n",
    "            WINDOW_SIZE = 50 # cut up the data every 5 seconds (10Hz)\n",
    "            STEP_SIZE = 5 # 0.5 second overlap so all gusts can be caught (moving the window 0.5 seconds at a time)\n",
    "\n",
    "            for i in range(0, len(df) - WINDOW_SIZE, STEP_SIZE):\n",
    "                # Add the labels (target)\n",
    "                window = df.iloc[i:i + WINDOW_SIZE]\n",
    "                features = extract_features(window)\n",
    "    \n",
    "                features['altitude(m)'] = altitude\n",
    "                features['file_name'] = file_path.stem\n",
    "                windowed_data.append(features)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path.name}: {e}\")\n",
    "\n",
    "    return pd.DataFrame(windowed_data).sort_values('file_name')\n",
    "windowed_df = apply_window_to_usable_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7406af16-2220-4619-a129-bc8109ca54ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# push to csv\n",
    "aggregate_df.to_csv('aggregate_data.csv', index=False) \n",
    "windowed_df.to_csv('windowed_data.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c8618d-21c4-45bb-b592-e881d874c6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_df.groupby('altitude(m)')[['tilt_avg']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5833e3c-2035-47d4-abb6-39edf18b75ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seeing which values matter most to determining altitude\n",
    "# inititally these results look a little disappointing, but I have a theory that the wind shear is not linear.\n",
    "# We'll use a random forest decision tree to get the real pattern out of these variables in another notebook.\n",
    "\n",
    "aggregate_df.drop(columns={'file_name', 'flight_time(seconds)'}).corr()['altitude(m)'].sort_values(ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
